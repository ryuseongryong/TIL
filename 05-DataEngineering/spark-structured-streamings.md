- https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html

# Overview
구조화된 스트리밍은 Spark SQL 엔진을 기반으로 구축된 확장 가능하고 내결함성이 뛰어난 스트림 처리 엔진입니다. 정적 데이터에 대한 일괄 계산을 표현하는 것과 동일한 방식으로 스트리밍 계산을 표현할 수 있습니다. Spark SQL 엔진은 스트리밍 데이터가 계속 도착함에 따라 이를 점진적이고 지속적으로 실행하고 최종 결과를 업데이트하는 작업을 처리합니다. Scala, Java, Python 또는 R에서 데이터 세트/데이터 프레임 API를 사용하여 스트리밍 집계, 이벤트 시간 창, 스트림-배치 조인 등을 표현할 수 있습니다. 계산은 최적화된 동일한 Spark SQL 엔진에서 실행됩니다. 마지막으로, 이 시스템은 체크포인트와 미리 쓰기 로그를 통해 엔드 투 엔드 정확히 한 번 내결함성을 보장합니다. 요컨대, 구조화된 스트리밍은 사용자가 스트리밍에 대해 추론할 필요 없이 빠르고 확장 가능하며 내결함성을 갖춘 엔드투엔드 정확히 한 번 스트림 처리를 제공합니다.

내부적으로, 기본적으로 구조화된 스트리밍 쿼리는 데이터 스트림을 일련의 작은 배치 작업으로 처리하는 마이크로 배치 처리 엔진을 사용하여 처리되므로 100밀리초의 낮은 엔드투엔드 지연 시간과 정확한 1회 내결함성을 보장합니다. 하지만 Spark 2.3부터는 연속 처리라는 새로운 저지연 처리 모드를 도입하여 최소 1밀리초의 엔드투엔드 지연 시간을 달성하고 최소 1회 내결함성을 보장할 수 있게 되었습니다. 쿼리에서 데이터 세트/데이터 프레임 작업을 변경하지 않고도 애플리케이션 요구사항에 따라 모드를 선택할 수 있습니다.

이 가이드에서는 프로그래밍 모델과 API에 대해 안내해 드리겠습니다. 기본 마이크로 배치 처리 모델을 중심으로 개념을 설명한 다음 나중에 연속 처리 모델에 대해 설명하겠습니다. 먼저 구조화된 스트리밍 쿼리의 간단한 예제인 스트리밍 단어 수부터 시작하겠습니다.

# Programming Model
구조화된 스트리밍의 핵심 아이디어는 라이브 데이터 스트림을 지속적으로 추가되는 테이블로 취급하는 것입니다. 이는 배치 처리 모델과 매우 유사한 새로운 스트림 처리 모델로 이어집니다. 스트리밍 연산을 정적 테이블에서와 같이 표준 배치와 같은 쿼리로 표현하면, Spark는 이를 무제한 입력 테이블에서 증분 쿼리로 실행합니다. 이 모델을 좀 더 자세히 이해해 보겠습니다.

## Basic Concepts
입력 데이터 스트림을 "입력 테이블"로 간주합니다. 스트림에 도착하는 모든 데이터 항목은 입력 테이블에 새로운 행이 추가되는 것과 같습니다.

https://spark.apache.org/docs/latest/img/structured-streaming-stream-as-a-table.png

입력에 대한 쿼리는 "결과 테이블"을 생성합니다. 트리거 간격마다(예를 들어, 1초마다) 새 행이 입력 테이블에 추가되고, 이는 결국 결과 테이블을 업데이트합니다. 결과 테이블이 업데이트될 때마다 변경된 결과 행을 외부 싱크에 쓰고 싶을 것입니다.

https://spark.apache.org/docs/latest/img/structured-streaming-model.png

"출력"은 외부 저장소에 기록되는 내용을 정의합니다. 출력은 다른 모드로 정의할 수 있습니다:

- Complete Mode(완료 모드) - 업데이트된 전체 결과 테이블이 외부 저장소에 기록됩니다. 전체 테이블의 쓰기를 처리하는 방법은 스토리지 커넥터가 결정합니다.

- Append Mode(추가 모드) - 마지막 트리거 이후 결과 테이블에 추가된 새 행만 외부 저장소에 기록됩니다. 이 모드는 결과 테이블의 기존 행이 변경되지 않을 것으로 예상되는 쿼리에만 적용됩니다.

- Update Mode(업데이트 모드) - 마지막 트리거 이후 결과 테이블에서 업데이트된 행만 외부 저장소에 기록됩니다(Spark 2.1.1부터 사용 가능). 이 모드는 마지막 트리거 이후 변경된 행만 출력한다는 점에서 전체 모드와 다릅니다. 쿼리에 집계가 포함되지 않은 경우, 추가 모드와 동일합니다.

각 모드는 특정 유형의 쿼리에만 적용된다는 점에 유의하세요. 이에 대해서는 나중에 자세히 설명합니다.

이 모델의 사용법을 설명하기 위해 위의 빠른 예제의 맥락에서 모델을 이해해 보겠습니다. 첫 번째 줄 DataFrame은 입력 테이블이고, 마지막 wordCounts DataFrame은 결과 테이블입니다. 스트리밍 라인에 대한 쿼리 DataFrame에서 wordCounts를 생성하는 것은 정적 데이터 프레임과 완전히 동일하다는 점에 유의하세요. 그러나 이 쿼리가 시작되면 Spark는 소켓 연결에서 새 데이터가 있는지 계속 확인합니다. 새 데이터가 있는 경우, Spark는 아래와 같이 이전에 실행 중인 카운트와 새 데이터를 결합하여 업데이트된 카운트를 계산하는 "증분" 쿼리를 실행합니다.

https://spark.apache.org/docs/latest/img/structured-streaming-example-model.png

구조화된 스트리밍은 전체 테이블을 구체화하지 않는다는 점에 유의하세요. 스트리밍 데이터 소스에서 사용 가능한 최신 데이터를 읽고, 이를 점진적으로 처리하여 결과를 업데이트한 다음 소스 데이터를 버립니다. 결과를 업데이트하는 데 필요한 최소한의 중간 상태 데이터만 유지합니다(예: 앞의 예제에서 중간 카운트).

이 모델은 다른 많은 스트림 처리 엔진과 크게 다릅니다. 많은 스트리밍 시스템에서는 사용자가 직접 실행 중인 집계를 유지 관리해야 하므로 내결함성 및 데이터 일관성(최소 한 번, 최대 한 번 또는 정확히 한 번)에 대해 추론해야 합니다. 이 모델에서는 새로운 데이터가 있을 때 Spark가 결과 테이블을 업데이트하여 사용자가 추론해야 하는 부담을 덜어줍니다. 예를 들어, 이 모델이 이벤트 시간 기반 처리와 늦게 도착하는 데이터를 어떻게 처리하는지 살펴보겠습니다.

## Handling Event-time and Late Data
이벤트 시간은 데이터 자체에 포함된 시간입니다. 많은 애플리케이션에서 이 이벤트 시간을 기준으로 작업을 수행하고자 할 수 있습니다. 예를 들어, IoT 장치에서 매분 생성되는 이벤트의 수를 얻고자 하는 경우, Spark가 이벤트를 수신하는 시간이 아니라 데이터가 생성된 시간(즉, 데이터의 이벤트 시간)을 사용하고 싶을 것입니다. 이 모델에서 이 이벤트 시간은 매우 자연스럽게 표현됩니다. 장치의 각 이벤트는 테이블의 행이고, 이벤트 시간은 행의 열 값입니다. 따라서 창 기반 집계(예: 매분 이벤트 수)는 이벤트 시간 열에 대한 특수한 유형의 그룹화 및 집계일 뿐이며, 각 시간 창은 하나의 그룹이고 각 행은 여러 창/그룹에 속할 수 있습니다. 따라서 이러한 이벤트 시간 창 기반 집계 쿼리는 정적 데이터 세트(예: 수집된 디바이스 이벤트 로그)와 데이터 스트림 모두에서 일관되게 정의할 수 있으므로 사용자의 작업이 훨씬 쉬워집니다.

또한, 이 모델은 이벤트 시간을 기준으로 예상보다 늦게 도착한 데이터도 자연스럽게 처리합니다. Spark는 결과 테이블을 업데이트하기 때문에 늦은 데이터가 있을 때 이전 집계를 업데이트하는 것은 물론, 중간 상태 데이터의 크기를 제한하기 위해 이전 집계를 정리하는 것도 완전히 제어할 수 있습니다. Spark 2.1부터는 사용자가 늦은 데이터의 임계값을 지정하고 엔진이 그에 따라 오래된 상태를 정리할 수 있는 워터마킹을 지원합니다. 이에 대해서는 나중에 창 작업 섹션에서 자세히 설명합니다.

## Fault Tolerance Semantics
엔드 투 엔드 정확한 1회성 시맨틱을 제공하는 것이 구조화된 스트리밍 설계의 핵심 목표 중 하나였습니다. 이를 달성하기 위해 구조화된 스트리밍 소스, 싱크, 실행 엔진이 처리의 정확한 진행 상황을 안정적으로 추적하여 재시작 및/또는 재처리를 통해 모든 종류의 장애를 처리할 수 있도록 설계했습니다. 모든 스트리밍 소스에는 스트림의 읽기 위치를 추적하기 위한 오프셋(카프카 오프셋 또는 키네시스 시퀀스 번호와 유사)이 있는 것으로 가정합니다. 엔진은 체크포인트와 미리 쓰기 로그를 사용해 각 트리거에서 처리되는 데이터의 오프셋 범위를 기록합니다. 스트리밍 싱크는 재처리를 처리하는 데 무능력하도록 설계되었습니다. 재생 가능한 소스와 비동성 싱크를 함께 사용하면 구조화된 스트리밍은 어떤 장애가 발생하더라도 엔드투엔드의 정확한 1회성 시맨틱을 보장할 수 있습니다.

# API using Datasets and DataFrames
Spark 2.0부터 데이터프레임과 데이터셋은 정적, 제한이 있는 데이터뿐만 아니라 스트리밍, 제한이 없는 데이터도 표현할 수 있습니다. 정적 데이터세트/데이터프레임과 마찬가지로, 공통 진입점인 SparkSession(Scala/Java/Python/R 문서)을 사용하여 스트리밍 소스에서 스트리밍 데이터프레임/데이터세트를 생성하고 정적 데이터프레임/데이터세트와 동일한 연산을 적용할 수 있습니다. 데이터세트/데이터프레임에 익숙하지 않다면 데이터프레임/데이터세트 프로그래밍 가이드를 통해 익숙해지는 것을 적극 권장합니다.

## Creating streaming DataFrames and streaming Datasets
스트리밍 데이터프레임은 SparkSession.readStream()이 반환하는 DataStreamReader 인터페이스(Scala/Java/Python 문서)를 통해 만들 수 있습니다. R에서는 read.stream() 메서드를 사용합니다. 정적 데이터 프레임을 생성하기 위한 읽기 인터페이스와 유사하게, 데이터 형식, 스키마, 옵션 등 소스의 세부 사항을 지정할 수 있습니다.

### Input Sources
몇 가지 기본 제공 소스가 있습니다.

- 파일 소스 - 디렉터리에 기록된 파일을 데이터 스트림으로 읽습니다. 파일은 파일 수정 시간 순서대로 처리됩니다. 최신순으로 설정하면 순서가 뒤바뀝니다. 지원되는 파일 형식은 텍스트, CSV, JSON, ORC, Parquet입니다. 각 파일 형식에 대한 최신 목록과 지원되는 옵션은 DataStreamReader 인터페이스의 문서를 참조하세요. 파일은 지정된 디렉토리에 원자 단위로 배치되어야 하며, 대부분의 파일 시스템에서 파일 이동 작업을 통해 이를 수행할 수 있습니다.

- 카프카 소스 - 카프카에서 데이터를 읽습니다. Kafka 브로커 버전 0.10.0 이상과 호환됩니다. 자세한 내용은 Kafka 연동 가이드를 참조하세요.

- 소켓 소스(테스트용) - 소켓 연결에서 UTF8 텍스트 데이터를 읽습니다. 수신 서버 소켓은 드라이버에 있습니다. 이것은 엔드 투 엔드 내결함성을 보장하지 않으므로 테스트용으로만 사용해야 합니다.

- 속도 소스(테스트용) - 초당 지정된 행 수로 데이터를 생성하며, 각 출력 행에는 타임스탬프와 값이 포함됩니다. 여기서 타임스탬프는 메시지 발송 시간을 포함하는 타임스탬프 유형이고, 값은 첫 번째 행부터 0부터 시작하여 메시지 수를 포함하는 긴 유형입니다. 이 소스는 테스트 및 벤치마킹을 위한 것입니다.

- 마이크로 배치당 속도 소스(테스트용) - 마이크로 배치당 지정된 수의 행으로 데이터를 생성하며, 각 출력 행에는 타임스탬프와 값이 포함됩니다. 여기서 타임스탬프는 메시지 발송 시간을 포함하는 타임스탬프 유형이고, 값은 첫 번째 행부터 0부터 시작하여 메시지 수를 포함하는 긴 유형입니다. 이 데이터 소스는 속도 데이터 소스와 달리 쿼리 실행(트리거 구성, 쿼리 지연 등)에 관계없이 마이크로 배치당 일관된 입력 행 세트를 제공합니다(예: 배치 0은 0~999, 배치 1은 1000~1999 등). 생성된 시간도 마찬가지입니다. 이 소스는 테스트 및 벤치마킹을 위한 것입니다.

일부 소스는 장애 발생 후 체크포인트 오프셋을 사용하여 데이터를 재생할 수 있다는 것을 보장하지 않기 때문에 내결함성이 없습니다. 내결함성 의미에 대한 이전 섹션을 참조하세요. 다음은 Spark의 모든 소스에 대한 세부 정보입니다.

- File source(Fault-tolerant yes)
    경로: 입력 디렉토리의 경로이며 모든 파일 형식에 공통입니다.
    최대 파일 수: 모든 트리거에서 고려할 새 파일의 최대 개수(기본값: 최대 없음)
    latestFirst: 최신 새 파일을 먼저 처리할지 여부로, 파일 백로그가 많을 때 유용합니다(기본값: false).
    fileNameOnly: 전체 경로 대신 파일 이름만 기준으로 새 파일을 확인할지 여부(기본값: false). 이 옵션을 `true`로 설정하면 다음 파일은 파일명인 "dataset.txt"가 동일하므로 동일한 파일로 간주됩니다:
    "file:///dataset.txt"
    "s3://a/dataset.txt"
    "s3n://a/b/dataset.txt"
    "S3A://A/B/C/DATASET.TXT"
    최대 파일 나이: 이 디렉토리에서 무시되기 전에 찾을 수 있는 파일의 최대 나이입니다. 첫 번째 배치의 경우 모든 파일이 유효한 것으로 간주됩니다. 최신 파일이 `true`로 설정되어 있고 최대 파일이 트리거별로 설정되어 있으면 유효하지만 처리해야 하는 오래된 파일은 무시될 수 있으므로 이 매개 변수는 무시됩니다. 최대 보존 기간은 현재 시스템의 타임스탬프가 아닌 최신 파일의 타임스탬프를 기준으로 지정됩니다.(기본값: 1주일).
    cleanSource: 처리 후 완료된 파일을 정리하는 옵션입니다.
    사용 가능한 옵션은 "보관", "삭제", "끄기"입니다. 옵션을 제공하지 않으면 기본값은 "꺼짐"입니다.
    "아카이브"를 제공하면 추가 옵션인 sourceArchiveDir도 함께 제공해야 합니다. "sourceArchiveDir"의 값은 소스 패턴의 깊이(루트 디렉터리로부터의 디렉터리 수)와 일치하지 않아야 하며, 여기서 깊이는 두 경로의 최소 깊이입니다. 이렇게 하면 아카이브된 파일이 새 소스 파일로 포함되지 않습니다.
    예를 들어, 소스 패턴으로 '/hello?/spark/*'를 제공한다고 가정하면, '/hello?/spark/*'와 '/hello1/spark/archive'가 일치하므로 '/hello1/spark/archive/dir'는 "sourceArchiveDir"의 값으로 사용할 수 없습니다. '/hello1/spark'는 '/hello?/spark'와 '/hello1/spark'가 일치하므로 "sourceArchiveDir"의 값으로도 사용할 수 없습니다. '/archived/here'는 일치하지 않으므로 괜찮습니다.
    Spark는 소스 파일을 자체 경로에 따라 이동합니다. 예를 들어, 소스 파일의 경로가 /a/b/dataset.txt이고 아카이브 디렉터리의 경로가 /archived/here인 경우, 파일은 /archived/here/a/b/dataset.txt로 이동됩니다.
    참고: 아카이브(이동을 통해) 또는 완료된 파일 삭제 모두 각 마이크로 배치에서 오버헤드(별도의 스레드에서 발생하더라도 속도 저하)가 발생하므로 이 옵션을 활성화하기 전에 파일 시스템에서 각 작업에 대한 비용을 이해해야 합니다. 반면에 이 옵션을 활성화하면 비용이 많이 드는 작업인 소스 파일 나열 비용을 줄일 수 있습니다.
    완료된 파일 클리너에 사용되는 스레드 수는 spark.sql.streaming.fileSource.cleaner.numThreads로 구성할 수 있습니다(기본값: 1).
    참고 2: 이 옵션을 활성화할 때 여러 소스 또는 쿼리에서 소스 경로를 사용해서는 안 됩니다. 마찬가지로 소스 경로가 파일 스트림 싱크의 출력 디렉터리에 있는 어떤 파일과도 일치하지 않아야 합니다.
    참고 3: 삭제 및 이동 작업 모두 최선의 노력을 기울여야 합니다. 파일을 삭제하거나 이동하지 못해도 스트리밍 쿼리가 실패하지는 않습니다. 애플리케이션이 정상적으로 종료되지 않거나, 정리할 파일이 너무 많이 대기열에 있는 경우 등 일부 상황에서는 Spark가 일부 소스 파일을 정리하지 못할 수 있습니다.

    파일 형식별 옵션은 DataStreamReader(Scala/Java/Python/R)의 관련 메서드를 참조하세요. 예를 들어, "parquet" 형식 옵션의 경우 DataStreamReader.parquet()를 참조하세요.

    또한 특정 파일 형식에 영향을 주는 세션 구성이 있습니다. 자세한 내용은 SQL 프로그래밍 가이드를 참조하십시오. 예를 들어, "parquet"의 경우 Parquet 구성 섹션을 참조하십시오.

- Socket Source(Fault-tolerant no)
    host: 연결할 호스트, 반드시 지정해야 함
    port: 연결할 포트, 반드시 지정해야 합니다.

- Rate Source(Fault-tolerant yes)
    행 수(예: 100, 기본값: 1)로 설정합니다: 초당 생성할 행의 수입니다.

    램프업 시간(예: 5초, 기본값: 0초): 생성 속도가 행당 초수가 되기 전까지 램프업할 시간입니다. 초보다 더 세밀한 단위를 사용하면 정수 초로 잘립니다.

    numPartitions(예: 10, 기본값: 스파크의 기본 병렬 처리): 생성된 행의 파티션 번호입니다.

    소스는 행당 초 수에 도달하기 위해 최선을 다하지만 쿼리의 리소스 제약이 있을 수 있으며, 원하는 속도에 도달하기 위해 numPartitions를 조정할 수 있습니다.

- Rate Per Micro-Batch Source (format: rate-micro-batch, Fault-tolerant yes)
    행 수(예: 100)로 설정합니다: 마이크로 배치당 생성해야 하는 행 수입니다.

    numPartitions(예: 10, 기본값: Spark의 기본 병렬 처리): 생성된 행의 파티션 번호입니다.

    startTimestamp(예: 1000, 기본값: 0): 생성된 시간의 시작 값입니다.

    advanceMillisPerBatch(예: 1000, 기본값: 1000): 각 마이크로 배치에서 생성된 시간에서 전진하는 시간입니다.

- Kafka Source(Fault-tolerant yes)
    https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html

### Schema inference and partition of streaming DataFrames/Datasets
기본적으로 파일 기반 소스에서 구조화된 스트리밍을 사용하려면 스키마를 자동으로 추론하는 Spark에 의존하지 않고 사용자가 직접 지정해야 합니다. 이 제한은 장애가 발생하는 경우에도 스트리밍 쿼리에 일관된 스키마가 사용되도록 보장합니다. 임시 사용 사례의 경우, spark.sql.streaming.schemaInference를 true로 설정하여 스키마 추론을 다시 활성화할 수 있습니다.

키=값/이라는 이름의 하위 디렉터리가 있을 때 파티션 검색이 수행되며 목록은 이러한 디렉터리로 자동으로 재귀됩니다. 이러한 열이 사용자 제공 스키마에 나타나면 읽은 파일의 경로에 따라 Spark에서 해당 열을 채웁니다. 파티셔닝 스키마를 구성하는 디렉터리는 쿼리가 시작될 때 존재해야 하며 정적으로 유지되어야 합니다. 예를 들어, /데이터/연도=2015/가 있을 때 /데이터/연도=2016/를 추가하는 것은 괜찮지만, 파티셔닝 열을 변경하는 것은 유효하지 않습니다(예: /데이터/날짜=2016-04-17/ 디렉터리를 생성하는 것).

## Operations on streaming DataFrames/Datasets
스트리밍 데이터프레임/데이터세트에 타입이 지정되지 않은 SQL과 유사한 연산(예: select, where, groupBy)부터 타입이 지정된 RDD와 유사한 연산(예: map, filter, flatMap)까지 모든 종류의 연산을 적용할 수 있습니다. 자세한 내용은 SQL 프로그래밍 가이드를 참조하세요. 사용할 수 있는 몇 가지 연산의 예를 살펴보겠습니다.

### Basic Operations - Selection, Projection, Aggregation
데이터프레임/데이터셋에 대한 대부분의 일반적인 연산이 스트리밍에 지원됩니다. 지원되지 않는 몇 가지 연산은 이 섹션의 뒷부분에서 설명합니다.

스트리밍 데이터프레임/데이터셋을 임시 뷰로 등록한 다음 SQL 명령을 적용할 수도 있습니다.

참고로, 데이터프레임/데이터셋에 스트리밍 데이터가 있는지 여부는 df.isStreaming을 사용하여 확인할 수 있습니다.

Spark가 스트리밍 데이터 세트에 대한 SQL 문을 해석하는 동안 상태 저장 연산을 삽입할 수 있으므로 쿼리의 쿼리 계획을 확인해야 할 수 있습니다. 쿼리 계획에 상태 저장소 연산이 삽입되면, 상태 저장소 연산에 대한 고려 사항으로 쿼리를 확인해야 할 수도 있습니다. (예: 출력 모드, 워터마크, 상태 저장소 크기 유지 등).

### Window Operations on Event Time
슬라이딩 이벤트 시간 창에 대한 집계는 구조화된 스트리밍을 사용하면 간단하며 그룹화된 집계와 매우 유사합니다. 그룹화된 집계에서는 사용자가 지정한 그룹화 열의 각 고유 값에 대해 집계 값(예: 카운트)이 유지됩니다. 창 기반 집계에서는 행의 이벤트 시간이 속하는 각 창에 대해 집계 값이 유지됩니다. 그림을 통해 이를 이해해 보겠습니다.

간단한 예시를 수정하여 이제 스트림에 행이 생성된 시간과 함께 행이 포함된다고 가정해 보겠습니다. 단어 수를 실행하는 대신 10분 단위로 단어 수를 계산하고 5분마다 업데이트하려고 합니다. 즉, 12:00 - 12:10, 12:05 - 12:15, 12:10 - 12:20 등의 10분 창 사이에 수신된 단어의 단어 수를 계산합니다. 12:00 - 12:10은 12:00 이후에 도착했지만 12:10 이전에 도착한 데이터를 의미합니다. 이제 12:07에 수신된 단어를 생각해 봅시다. 이 단어는 12:00 - 12:10 및 12:05 - 12:15의 두 창에 해당하는 카운트를 증가시켜야 합니다. 따라서 카운트는 그룹화 키(즉, 단어)와 창(이벤트 시간에서 계산 가능) 모두에 의해 색인화됩니다.

결과 테이블은 다음과 같이 표시됩니다.

https://spark.apache.org/docs/latest/img/structured-streaming-window.png

#### Handling Late Data and Watermarking
이제 이벤트 중 하나가 애플리케이션에 늦게 도착하면 어떻게 되는지 생각해 보세요. 예를 들어 12:04에 생성된 단어(즉, 이벤트 시간)가 애플리케이션에 12:11에 수신될 수 있다고 가정해 보겠습니다. 애플리케이션은 12:11 대신 12:04라는 시간을 사용하여 12:00 - 12:10 기간의 이전 카운트를 업데이트해야 합니다. 이는 창 기반 그룹화에서 자연스럽게 발생합니다. 구조화된 스트리밍은 부분 집계에 대한 중간 상태를 장기간 유지할 수 있으므로 아래 그림과 같이 최신 데이터가 이전 창의 집계를 올바르게 업데이트할 수 있습니다.

https://spark.apache.org/docs/latest/img/structured-streaming-late-data.png

그러나 이 쿼리를 며칠 동안 실행하려면 시스템이 누적되는 중간 인메모리 상태의 양을 제한해야 합니다. 즉, 애플리케이션이 해당 집계에 대한 최신 데이터를 더 이상 수신하지 않기 때문에 시스템은 오래된 집계가 인메모리 상태에서 삭제될 수 있는 시점을 알아야 합니다. 이를 위해 Spark 2.1에서는 엔진이 데이터의 현재 이벤트 시간을 자동으로 추적하고 그에 따라 오래된 상태를 정리할 수 있는 워터마킹을 도입했습니다. 이벤트 시간 열과 이벤트 시간 측면에서 데이터가 얼마나 늦을 것으로 예상되는지에 대한 임계값을 지정하여 쿼리의 워터마크를 정의할 수 있습니다. 시간 T로 끝나는 특정 기간의 경우, 엔진은 상태를 유지하고 늦은 데이터는 (엔진이 볼 수 있는 최대 이벤트 시간 - 늦은 임계값 > T)까지 상태를 업데이트할 수 있도록 허용합니다. 즉, 임계값 이내의 늦은 데이터는 집계되지만 임계값보다 늦은 데이터는 삭제되기 시작합니다(정확한 보장은 이 섹션의 뒷부분 참조). 예시를 통해 이를 이해해 보겠습니다. 이전 예제에서 워터마킹을 정의하는 방법은 아래와 같이 withWatermark()를 사용하여 쉽게 정의할 수 있습니다.

이 예에서는 쿼리의 워터마크를 "타임스탬프" 열의 값에 정의하고, 데이터가 얼마나 늦게 허용되는지에 대한 임계값으로 "10분"을 정의하고 있습니다. 이 쿼리가 업데이트 출력 모드(나중에 출력 모드 섹션에서 설명)에서 실행되는 경우 엔진은 결과 테이블에서 창이 워터마크보다 오래되어 "타임스탬프" 열의 현재 이벤트 시간보다 10분 뒤처질 때까지 창 수를 계속 업데이트합니다. 다음은 그림입니다.

https://spark.apache.org/docs/latest/img/structured-streaming-watermark-update-mode.png

그림에서 보듯이 엔진이 추적한 최대 이벤트 시간은 파란색 점선이고, 모든 트리거가 시작될 때 (최대 이벤트 시간 - '10분')으로 설정된 워터마크는 빨간색 선입니다. 예를 들어, 엔진이 데이터(12:14, 개)를 관찰하면 다음 트리거의 워터마크를 12:04로 설정합니다. 이 워터마크는 엔진이 10분 동안 중간 상태를 유지하여 늦은 데이터를 계산할 수 있도록 합니다. 예를 들어, 데이터(12:09, 고양이)는 순서가 맞지 않고 늦어 12:00 - 12:10 및 12:05 - 12:15에 해당합니다. 트리거의 워터마크인 12:04보다 여전히 앞서 있기 때문에 엔진은 중간 카운트를 상태로 유지하고 관련 윈도우의 카운트를 올바르게 업데이트합니다. 그러나 워터마크가 12:11로 업데이트되면 창(12:00 - 12:10)의 중간 상태가 지워지고 이후의 모든 데이터(예: (12:04, 당나귀))는 "너무 늦은" 것으로 간주되어 무시됩니다. 모든 트리거 후에 업데이트된 카운트(즉, 보라색 행)는 업데이트 모드에서 지정한 대로 트리거 출력으로 싱크에 기록된다는 점에 유의하세요.

일부 싱크(예: 파일)는 업데이트 모드에 필요한 세분화된 업데이트를 지원하지 않을 수 있습니다. 이러한 싱크와 함께 작업하기 위해 최종 카운트만 싱크에 기록하는 추가 모드도 지원합니다. 아래 그림과 같습니다.

스트리밍이 아닌 데이터 세트에서 워터마크와 함께 사용하면 안 된다는 점에 유의하세요. 워터마크가 배치 쿼리에 어떤 식으로든 영향을 미치지 않아야 하므로 직접 무시합니다.

https://spark.apache.org/docs/latest/img/structured-streaming-watermark-append-mode.png

앞서 설명한 업데이트 모드와 마찬가지로 엔진은 각 창에 대한 중간 카운트를 유지합니다. 그러나 부분 카운트는 결과 테이블에 업데이트되지 않고 싱크에 기록되지 않습니다. 엔진은 늦은 날짜가 카운트될 때까지 "10분"을 기다린 다음, 윈도우의 중간 상태 < 워터마크를 삭제하고 최종 카운트를 결과 테이블/싱크에 추가합니다. 예를 들어, 12:00 - 12:10 윈도우의 최종 카운트는 워터마크가 12:11로 업데이트된 후에만 결과 테이블에 추가됩니다.

#### Type of time windows
스파크는 텀블링(고정), 슬라이딩 및 세션의 세 가지 시간 창을 지원합니다.

https://spark.apache.org/docs/latest/img/structured-streaming-time-window-types.jpg

텀블링 윈도우는 고정된 크기의 겹치지 않는 연속적인 시간 간격으로 이루어진 일련의 창입니다. 입력은 하나의 창에만 바인딩할 수 있습니다.

슬라이딩 윈도우는 '고정된 크기'라는 점에서 텀블링 윈도우와 유사하지만, 슬라이드 기간이 윈도우 기간보다 짧으면 윈도우가 겹칠 수 있으며, 이 경우 입력이 여러 개의 윈도우에 바인딩될 수 있습니다.

텀블링 및 슬라이딩 창은 위의 예제에서 설명한 창 기능을 사용합니다.

세션 창은 앞의 두 가지 유형에 비해 다른 특징이 있습니다. 세션 창은 입력에 따라 창 길이의 크기가 동적으로 달라집니다. 세션 창은 입력과 함께 시작되며, 갭 기간 내에 다음 입력이 수신되면 스스로 확장됩니다. 정적 갭 기간의 경우, 최신 입력을 받은 후 갭 기간 내에 입력이 없으면 세션 창이 닫힙니다.

세션 창은 세션_창 함수를 사용합니다. 이 함수의 사용법은 창 함수와 유사합니다.

정적 값 대신 입력 행에 따라 동적으로 간격 기간을 지정하는 표현식을 제공할 수도 있습니다. 간격 기간이 음수이거나 0인 행은 집계에서 필터링된다는 점에 유의하세요.

동적 간격 기간을 사용하면 세션 창을 닫을 때 더 이상 최신 입력에 의존하지 않습니다. 세션 창의 범위는 이벤트 시작 시간과 쿼리 실행 중 평가된 간격 기간에 의해 결정되는 모든 이벤트 범위의 합입니다.

스트리밍 쿼리에서 세션 창을 사용할 때는 아래와 같이 몇 가지 제한 사항이 있습니다:

- "출력 모드로 '업데이트 모드'는 지원되지 않습니다.
- 그룹화 키에 세션_창 외에 하나 이상의 열이 있어야 합니다. 일괄 쿼리의 경우, 전역 창(그룹화 키에 세션_창만 있는 경우)이 지원됩니다.

기본적으로 Spark는 세션 창 집계를 위해 부분 집계를 수행하지 않습니다. 그룹화하기 전에 로컬 파티션에서 추가 정렬이 필요하기 때문입니다. 로컬 파티션별로 동일한 그룹 키의 입력 행 수가 적은 경우에는 부분 집계가 더 효과적이지만, 로컬 파티션에 동일한 그룹 키를 가진 입력 행이 많은 경우에는 부분 집계를 수행해도 추가 정렬에도 불구하고 성능이 크게 향상될 수 있습니다.

spark.sql.streaming.sessionWindow.merge.sessions.in.local.partition을 활성화하여 스파크가 부분 집계를 수행하도록 지정할 수 있습니다.

https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#representation-of-the-time-for-time-window