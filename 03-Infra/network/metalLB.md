# MetalLB

## MetalLB with L2
- Speaker -> ARP req에 대한 res를 통해 LB 구현
    - 서비스의 endpoint(pod) -> node speaker가 ARP요청에 응답
    - 서비스의 endpoint가 2개 이상인 경우 하나의 노드에서 모든 요청 처리

```
metalLB를 설치하면 daemon 형태로 스피커가 설치돼요, daemonset이니까 모든 노드에 스피커 파드가 하나씩 설치가 돼요. L2 모드로 사용하면 어떻게 동작하냐면 스피커가 ARP request를 일종의 hijacking, intercepting을 해요. 

기본적으로 networking이 이루어지는 과정을 간단하게 요약하면, 클라이언트에서 240번으로 패킷을 보내려고 하면, 240번은 IP이다. IP networking을 위한 것이고, 실질적으로 패킷을 보내기 위해서는 MAC주소(L2주소)가 필요하다. 그러면 240번, 그러니까 같은 네트워크 대역, 우리가 IP 설정하면, 192.168.0.240을 설정하고, netmask를 설정한다. 255.255.255.0. 그래서 클라이언트와 서버가 같은 네트워크 주소 안에 있으면 서버의 MAC 주소를 알려달라는 것이 ARP 요청이다.

만약에 다른 네트워크에 있으면 라우터의 MAC 주소를 요청한다. 그래서 ARP로, default 라우터가 1번이면 1번의 MAC 주소를 알려달라고 한다. 그래서 실질적으로 패킷을 전달하는 것은 ARP 요청을 전달해서(요청을 날려서, broadcasting 해서) 응답을 해주는 놈의 MAC 주소로 패킷을 전달하는 것이다.

그래서 동작원리는 간단하다. 

K8S의 External IP는 서비스에 이미 할당 되어 있다. 

우리 같은 경우에는 IP range를 정해놓고, LB를 Static IP로 잡고 있다. 재설치할 때마다 바뀌면 안되기 때문에. 이 부분은 상황에 따라 다른 것이다.

(클라이언트가 이미 해당하는 서비스, 예를 들면 카프카 브로커 서비스에 접근하려고 하는 카프카 브로커 0번이)
클라이언트가 접근하려고 하는 kafka-broker service 0번이 노드 1번에 있다는 것을 이미 알고 있고, external IP가 240번이라는 것을 이미 알고 있으면 바로 240번으로 접근하면 된다. 그러면 같은 네트워크 대역 안에 있으니까, 240번으로 보내려고 클라이언트가 ARP request를 날릴 것이다. 그럼 240번의 MAC 주소달라는 요청을 할 것이고, MetalLB의 스피커가 노드 1번에 있는 것이 파드 3라는 것을 알고, 노드 1번에 있는 스피커가 ARP reply를 하고, 노드 1번의 MAC 주소가 클라이언트에게 전달된다. 이후 클라이언트는 노드1번의 MAC 주소로 요청을 보낼 것이다. 이렇게 동작하는 것이 L2모드이다. 말 그대로 ARP 패킷을 조작해서 우리가 원하는 목적을 달성하는 것이다. 

L2모드의 문제점은, 서비스에 파드 1개만 있는 것이 아니라, 하나의 서비스와 연결된 파드가 여러 개 설정되어 있을 것이다. 그러면 ARP request가 들어왔을 때 2~3가 동시에 reply할 수는 없다. 그래서 MetalLB L2는 2개 이상일 경우에 리더를 선출한다. 리더로 선출된 노드가 ARP reply를 한다. 문제는 리더에게만 패킷을 보내기 때문에 리더가 있는 노드를 무조건 거치게 되어있다. 따라서 네트워크 사용량이 일시적으로 증가하는 경우 트래픽을 모두 감당하지 못할 수 있다. 즉 load balancing은 되지 않는다고 볼 수 있다.

이런 문제를 해결하기 위해서 나온 것이 BGP모드.
```
```
- 리더 스피커 파드가 선출
- external IP를 리더 스피커 파드 소유라고 ARP 프로토콜로 전파
- 리더 스피커 파드로 트래픽이 오면 iptables에 의해 부하 분산(서비스가 파드를 가리키는 것처럼 동작)

L2모드는 리더 스피커 파드가 있고, 이 리더가 로드밸런서 external IP를 관리하게 됨. 그 원리는 "이 IP들을 내가(리더 스피커가 있는 노드) 관리하고 있다."고 리더스피커가 전파한다. 이 때 전파 방법이 ARP 프로토콜이다. 
```


## MetalLB란?
- MetalLB는 LoadBalancer 유형의 서비스를 모니터링하고 가상 풀에서 IP주소를 할당하는 Kubernetes-aware 솔루션이다.
- BGP(Border Gateway Protocol) 또는 L2(with ARP:Address Resolution Protocol)를 사용하여 서비스를 노출한다.
- MetalLB는 로컬 트래픽을 지원하므로 데이터를 수신하는 머신이 요청을 서비스하는 머신이 된다. 하나의 머신만 서비스에 대한 트래픽을 수신하고 다른 머신은 장애 조치에만 사용되므로 트래픽 워크로드가 많은 가상 IP를 사용하는 것은 권장되지 않는다.(L2모드)
- BGP는 이런 제한사항이 없으나 노드를 원자 단위로 간주한다. 즉 서비스가 5개 노드 중 2개 노드에서 실행 중인 경우 이 두 노드만 트래픽을 수신하지만, 노드 중 하나에는 3개의 파드가 있고 다른 노드에는 하나의 파드만 실행중인 경우에도 각각 트래픽의 50%를 수신한다. 노드 anti-affinity를 사용하여 K8S 파드가 단일 노드에 스택되지 않도록 하는 것이 좋다.

## 주소 할당
- 클라우드 공급자의 K8S 클러스터에서는 사용자가 로드 밸런서를 요청하면 클라우드 플랫폼이 사용자에게 IP 주소를 할당한다. 베어메탈 클러스터에서는 MetalLB가 해당 할당을 담당한다.
- MetalLB는 아무것도 없는 상태에서 IP 주소를 생성할 수 없으므로, 사용할 수 있는 IP주소 풀을 제공해야 한다. 서비스가 들어오고 나갈 때 개별 주소를 할당하고 할당을 취소하는 작업은 MetalLB가 처리하지만, 구성된 풀의 일부인 IP만 할당한다.
- MetalLB 용 IP 주소 풀을 얻는 방법은 사용중인 환경에 따라 다르다. colocation 시설에서 베어메탈 클러스터를 실행하는 경우, 호스팅 제공업체에서 임대용 IP 주소를 제공할 수 있다. 이 경우 `/26`의 IP공간(64개 주소)을 임대하고 클러스터 서비스를 위해 해당 범위를 MetalLB에 제공하면 된다.
- 또는 클러스터를 사설로 사용하여 인근 LAN에 서비스를 제공하지만 인터넷에 노출되지 않을 수도 있다. 이 경우 프라이빗 주소 공간 중 하나에서 IP 범위(RFC1918 주소)를 선택하고 이를 MetalLB에 할당할 수 있다. 이런 주소는 무료이고 LAN에 클러스터 서비스만 제공하는 수준에서 잘 동작한다.

## L2 mode
- L2 모드에서는 한 노드가 로컬 네트워크에 서비스를 광고하는 역할을 한다. 네트워크 관점에서 보면 해당 컴퓨터의 네트워크 인터페이스에 여러 개의 IP 주소가 할당된 것처럼 보인다.
- 내부적으로는 MetalLB는 IPv4 서비스에 대한 ARP 요청에 응답하고 IPv6에 대한 NDP 요청에 응답한다.
- L2 모드의 가장 큰 장점은 범용성이다. 특별한 하드웨어나 고급 라우터 없이도 모든 이더넷 네트워크에서 작동한다.

### 부하 분산 동작
- L2 모드에서는 서비스 IP에 대한 모든 트래픽이 하나의 노드로 이동한다. 거기서부터 kube-proxy는 트래픽을 모든 서비스의 파드로 분산시킨다.
- 그런 의미에서 L2는 로드밸런서를 구현하지 않는다. 대신 장애 조치 메커니즘을 구현하여 현재 리더 노드가 어떤 이유로 장애가 발생할 경우, 다른 노드가 인계받을 수 있도록 한다.
- 리더 노드가 어떤 이유로 장애가 발생하면 자동으로 장애 복구가 이루어진다. 멤버 리스트를 사용하여 장애가 발생한 노드를 감지하고, 이 시점에서 새로운 노드가 장애가 발생한 노드로부터 IP 주소의 소유권을 인수한다.

### 제한 사항
- L2 모드에는 단일 노드 병목 현상과 잠재적으로 느린 장애 조치라는 두 가지 주요 제한 사항이 있다.
- L2 모드에서는 리더로 선출된 단일 노드가 서비스 IP에 대한 모든 트래픽을 수신한다. 즉, 서비스의 수신 대역폭이 단일 노드의 대역폭으로 제한된다. 이는 트래픽을 조정하기 위해 ARP와 NDP를 사용할 때의 근본적인 한계이다.
- 구현에 따라 노드 간 장애 복구는 클라이언트의 협조에 따라 달라진다. 장애가 발생하면 MetalLB는 여러 개의 무료 L2 패킷(요청하지 않은 L2 패킷)을 전송하여 서비스 IP와의 연결된 MAC 주소가 변경되었음을 클라이언트에게 알린다.
- 대부분의 운영 체제는 '요청하지 않은' 패킷을 올바르게 처리하고 연결된 캐시를 즉시 업데이트한다. 이 경우 몇 초 내로 장애 복구가 이루어진다. 그러나 일부 시스템에는 '요청하지 않은' 패킷에 대한 처리를 전혀 구현하지 않거나 캐시 업데이트가 지연되는 버그가 있는 경우가 있고, 이 때는 장애 복구에 시간이 걸린다.
- 모든 최신 버전의 주요 OS는 L2 장애 조치를 올바르게 구현하므로 문제가 발생할 수 있는 유일한 상황은 구형, 일반적이지 않은 OS에서 발생한다.
    - 계획된 장애 조치가 버그가 있는 클라이언트에 미치는 영향을 최소화하려면 리더선출을 다시 시작한 다음 몇 분 동안 기존 리더 노드를 계속 가동하여 캐시가 새로 고쳐질 때까지 이전 클라이언트에 대한 트래픽을 계속 전달할 수 있도록 해야 한다.
    - 게획되지 않은 장애 조치 중에는 버그가 있는 클라이언트가 캐시 항목을 새로 고칠 때까지 서비스 IP에 연결할 수 없게 된다.

### Keepalived와 비교
- MetalLB의 L2 모드는 Keepalived와 유사한 점이 많기 때문에 Keepalived에 익숙하다면 이 모드가 상당히 익숙하게 들릴 것이다. 하지만 몇 가지 차이점이 있다.
- Keepalived는 Virtual Router Redundancy Protocol(VRRP)을 사용한다. Keepalived 인스턴스는 리더를 선택하고 해당 리더가 사라질 때를 알리기 위해 서로 VRRP 메시지를 지속적으로 교환한다.
- 반면 MetalLB는 클러스터의 노드에 더 이상 연결할 수 없는 시기와 해당 노드의 서비스 IP를 다른 곳으로 이동해야 하는 시기를 알기 위해 멤버 리스트를 사용한다.
- 장애가 발생하면 서비스 IP 주소가 한 컴퓨터에서 다른 컴퓨터로 마이그레이션되는 것 처럼 보이고, 나머지 시간에는 컴퓨터가 둘 이상의 IP 주소를 가지고 있는 것처럼 보일 뿐이다.
- MetalLBsms VRRP를 사용하지 않기 때문에 해당 프로토콜의 일부 제한이 적용되지 않는다. 예를 들어, 네트워크 당 255개의 로드 밸런서라는 VRRP 제한은 MetalLB에는 존재하지 않는다. 네트워크에 여유 IP가 있는 한 원하는 만큼 로드 밸런싱된 IP를 사용할 수 있다. 또한 MetalLB는 가상 라우터 ID가 없는 등 VRRP보다 구성이 덜 필요하다.
- 반대로 MetalLB는 클러스터 구성원 정보를 위해 구성원 목록에 의존하기 떄문에 타사 VRRP 인식 라우터 및 인프라와 상호 운용할 수 없다. 이는 의도한 대로 작동하고 있다.(MetalLB는 Kubernetes 클러스터 내에서 로드 밸런싱 및 장애 조치를 제공하도록 특별히 설계되었으며, 이 시나리오에서는 타사 LB 소프트웨어와의 상호 운용성이 적용되지 않습니다.)

## BGP mode

- BGP 모드에서 클러스터의 각 노드는 네트워크 라우터와 BGP 피어링 세션을 설정하고 해당 피어링 세션을 사용하여 외부 클러스터 서비스의 IP를 알려준다.
- 라우터가 다중 경로를 지원하도록 구성되어 있다고 가정하면, MetalLB가 게시한 경로는 nexthop을 제외하고 서로 동등하므로 진정한 LB이 가능하다. 즉 라우터가 모든 nexthop을 함께 사용하며 라우터 간 부하가 분산된다.
- 패킷이 노드에 도착한 후, kube-proxy는 트래픽 라우팅의 마지막 hop을 담당하여 패킷을 서비스의 특정 파드에 전달한다.
---
- 스피커가 BGP 라우팅 테이블을 등록해서 로드밸런싱 구현
    - 해당 서비스의 엔드포인트(파드)가 동작중인 노드의 스피커가 BGP 라우팅 테이블 등록
    - 해당 서비스의 엔드포인트가 2개 이상일 경우, 라우터가 제공하는 로드밸런싱 활용 가능
```
L2 모드가 ARP 통신을 기반으로 동작하는 것에서 오는 한계 때문에 나온 것이 BGP 모드.
라우터 프로토콜, 라우팅은 라우터끼리 주고 받는 프로토콜 중 하나. metalLB가 BGP 모드를 지원함.
스피커가 BGP로 라우터에 등록 -> 특정 IP를 어디로 전달하라고 지정함. 라우터를 타야해서 안 좋아 보일 수 있지만, 2개 이상의 엔드포인트를 지원함. 라우터에서 지원하는 ECMP 기능을 활용함. 브로커 서비스가 노드0, 1에 있는 상황에서 각각 BGP로 등록함. routing table에 240 -> 200,201 처리 가능 -> 라우팅 로드밸런싱 알고리즘으로 처리
```

### 부하 분산 동작
- 로드 밸런싱의 정확한 동작은 특정 라우터 모델과 구성에 따라 다르지만, 일반적인 동작은 패킷 해시를 기반으로 연결별로 밸런싱하는 것이다.
- 연결별이란 단일 TCP 또는 UDP 세션에 대한 모든 패킷이 클러스터의 단일 컴퓨터로 전달된다는 의미이다. 트래픽 분산은 한 연결 내의 패킷이 아니라 서로 다른 연결 사이에서만 발생한다.
- 여러 클러스터 노드에 패킷을 분산하면 여러 수준에서 동작이 저하될 수 있으므로 이는 장점이다.
    - 단일 연결을 여러 경로로 분산하면 와이어에서 패킷 재정렬이 발생하여 최종 호스트의 성능에 큰 영향을 미친다.
    - Kubernetes의 노드 내 트래픽 라우팅은 노드 간에 일관성이 보장되지 않는다. 즉 서로 다른 두 노드가 동일한 연결에 대한 패킷을 서로 다른 파드로 라우팅하기로 결정할 수 있으며, 이로 인해 연결 실패가 발생할 수 있다.
- 패킷 해싱은 고성능 라우터가 여러 백엔드에 걸쳐 state-less 방식으로 연결을 분산할 수 있는 방법이다. 각 패킷에 대해 일부 필드를 추출하고, 이를 seed로 사용하여 가능한 백엔드 중 하나를 결정론적으로 선택한다. 모든 필드가 동일하면 동일한 백엔드가 선택된다.
- 사용 가능한 정확한 해싱 방법은 라우터 하드웨어 및 소프트웨어에 따라 다릅니다. 일반적인 두 가지 옵션은 5-tuple, 3-tuple 해싱이다. 3-tuple 해싱은 프로토콜, source-ip, destination-ip를 키로 사용하므로 두 개의 고유 IP 사이의 모든 패킷이 동일한 백엔드로 이동한다. 5-tuple 해싱은 소스 및 대상 포트를 추가하여 동일한 클라이언트의 서로 다른 연결을 클러스터 전체에 분산할 수 있다.
- 일반적으로 패킷 해시에 가능한 한 많은 엔트로피를 넣는 것이 바람직하며, 이는 일반적으로 더 많은 필드를 사용하는 것이 좋다는 것을 의미한다. 엔트로피가 증가하면 모든 모드가 정확히 동일한 수의 패킷을 수신하는 이상적인 로드 밸런싱 상태에 가까워지기 때문이다. 위에 나열한 문제 때문에 이상적인 상태를 달성할 수 없지만, 가능한 한 연결을 고르게 분산시켜 핫스팟이 형성되는 것을 방지할 수 있다.

### 제한사항
- BGP를 로드 밸런싱 메커니즘으로 사용하면 맞춤형 로드 밸런서가 아닌 표준 라우터 하드웨어를 사용할 수 있다는 장점이 있지만 단점도 있다.
- 가장 큰 단점은 BGP 기반 부하 분산이 주소에 대해 설정된 백엔드 변경에 원활하게 반응하지 않는다는 것이다. 즉 클러스터 노드가 다운되면 서비스에 대한 모든 활성 연결이 끊어질 것으로 예상해야 한다.(사용자에게 "Connection reset by peer"라고 표시된다.)
- BGP 기반 라우터는 state-less LB를 구현한다. 패킷 헤더의 일부 필드를 해시하고 해당 해시를 사용 가능한 백엔드 배열의 인덱스로 사용하여 주어진 패킷을 특정 다음 hop에 할당한다.
- 문제는 라우터에 사용되는 해시가 일반적으로 안정적이지 않기 때문에 백엔드 세트의 크기가 변경될 때 마다(노드 BGP 세션이 다운될 때)기존 연결이 사실상 무작위로 다시 해시되며, 이는 기존 연결의 대부분이 해당 연결에 대해 전혀 알지 못하는 다른 백엔드로 갑자기 전달된다는 것을 의미한다.
- 그 결과 서비스에 대한 Ip -> 노드 매핑이 변경될 때마다 서비스에 대한 대부분의 활성 연결이 끊어지는 일회성 히트가 발생할 수 있다. 지속적인 패킷 손실이나 블랙홀딩은 없고, 한 번만 연결이 끊어진다.
- 서비스의 기능에 따라 몇 가지 완화된 전략을 사용할 수 있다.
    - BGP 라우터에는 보다 안정적이 ECMP 해싱 알고리즘을 사용할 수 있는 옵션이 있을 수 있다. 이를 탄력적 ECMP 또는 탄력적 LAG라고 부르기도 한다. 이런 알고리즘을 사용하면 백엔드 세트가 변경될 때 영향을 받는 연결 수를 크게 줄일 수 있다.
    - 서비스 배포를 특정 노드에 고정하여 신경써야 하는 노드 풀을 최소화할 수 있다. 
    - 대부분의 사용자가 사용하지 않는 트래픽이 적은 사용 시간대에 서비스 배포 변경을 예약하는 것이 좋다.
    - 각 논리적 서비스를 서로 다른 IP를 가진 두 개의 K8S 서비스로 분할하고, drained 서비스를 중단하기 전에 DNS를 사용하여 사용자 트래픽을 한 서비스에서 다른 서비스로 부드럽게 마이그레이션할 수 있다.
    - 클라이언트 측에 투명한 재시도 로직을 추가하여 갑작으러운 연결 끊김으로부터 gracefully 복구할 수 있다. 이는 클라이언트가 모바일 앱이나 풍부한 SPA과 같은 경우 특히 효과적이다.
    - 서비스를 인그레스 컨트롤러 뒤에 배치하는 방법도 있다. 인그레스 컨트롤러 자체는 MetalLB를 사용하여 트래픽을 수신할 수 있지만, BGP와 서비스 사이에 스테이트풀 레이어가 있으면 걱정 없이 서비스를 변경할 수 있다. 인그레스 컨트롤러 자체의 배포를 변경할 때만 주의하면 된다.(scale up을 위해 NGINX 파드 추가할 때)
    - 리셋 연결이 때때로 폭주할 수 있다는 것을 인지하고 있어야 한다. 가용성이 낮은 내부 서비스의 경우, 이는 그대로 허용될 수 있다.

## References
- https://metallb.universe.tf/concepts/layer2/
- https://en.wikipedia.org/wiki/Hop_(networking)
- https://medium.com/dataplatform-lab/k8s-kafka-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EC%B5%9C%EC%A0%81%ED%99%94-metallb-fa59729086ea
- https://malwareanalysis.tistory.com/271
- https://ubuntu.com/kubernetes/docs/metallb#:~:text=MetalLB%20is%20a%20Kubernetes%2Daware,Resolution%20Protocol
- https://www.youtube.com/watch?v=RnjKMYD8SKc
- https://metallb.universe.tf/concepts/bgp/