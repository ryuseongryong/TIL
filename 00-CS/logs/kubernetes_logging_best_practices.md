- https://www.cncf.io/blog/2023/07/03/kubernetes-logging-best-practices/

# Kubernetes logging best practices

첸나이의 데브옵스 엔지니어 Selvam R의 커뮤니티 게시물(KCD 첸나이 블로그톤 우승자)

Kubernetes는 컨테이너 오케스트레이션을 위한 인기 있는 오픈 소스 플랫폼으로, 컨테이너화된 애플리케이션을 배포하고 관리하기 위해 개발자와 DevOps 팀에서 널리 사용되고 있습니다. Kubernetes에서 애플리케이션을 실행하는 데 있어 중요한 측면 중 하나는 애플리케이션의 상태와 성능을 모니터링하고 문제를 신속하게 해결하는 데 도움이 되는 로깅입니다.

이 블로그에서는 Kubernetes 로깅과 Kubernetes 환경에서의 로깅 모범 사례에 대해 설명합니다.

## What is Kubernetes Logging?
Kubernetes 로깅은 Kubernetes 클러스터와 클러스터에서 실행 중인 애플리케이션에서 생성된 로그 데이터를 캡처하고 저장하는 프로세스를 말합니다. 이 데이터에는 애플리케이션 성능, 오류, 경고 및 기타 이벤트에 대한 정보가 포함됩니다. Kubernetes 로그는 분산 시스템의 문제를 디버깅하고 해결하는 데 중요하며 개발자, 운영자, 보안 팀이 애플리케이션 상태를 모니터링하고 유지하는 데 사용됩니다.

## How does Kubernetes Logging work?
Kubernetes 로그는 Kubernetes API 서버, kubelet, 컨테이너 런타임, 클러스터에서 실행 중인 애플리케이션 등 Kubernetes 클러스터의 다양한 구성 요소에 의해 생성됩니다. 이러한 로그는 Kubernetes 포드로 실행되는 로깅 에이전트에 의해 수집 및 집계되어 저장 및 분석을 위해 중앙 위치로 전송됩니다.

Kubernetes에서 가장 일반적으로 사용되는 로깅 에이전트는 Fluentd로, 로그 데이터를 수집, 변환, Elasticsearch, Splunk, Kafka를 비롯한 다양한 대상으로 전달할 수 있는 오픈 소스 데이터 수집기입니다. 다른 인기 있는 로깅 에이전트로는 Logstash와 Fluent Bit가 있습니다.

다음은 Fluentd를 사용한 로깅의 작동 방식에 대한 다이어그램입니다.
https://www.cncf.io/wp-content/uploads/2023/07/084tk47dlm4r32kdapsb.png

### Best Practices for Kubernetes Logging:

다음은 Kubernetes 환경에서 로깅을 위한 몇 가지 모범 사례입니다:

1. 중앙 집중식 로깅 솔루션 사용 - 중앙 집중식 로깅 솔루션을 사용하면 로그를 중앙 위치에 저장하고 분석할 수 있으므로 문제를 해결하고 애플리케이션 성능을 모니터링하기가 더 쉬워집니다. Elasticsearch, Splunk, Loggly는 Kubernetes와 함께 사용되는 몇 가지 인기 있는 중앙 집중식 로깅 솔루션입니다.
2. 로그 순환 구현 - 로그 순환은 디스크 공간이 가득 차는 것을 방지하기 위해 오래된 로그를 삭제하거나 보관하는 프로세스입니다. 디스크 공간이 부족해지지 않도록 Kubernetes 로그에 대해 로그 로테이션을 구성하는 것이 필수적입니다.
3. 구조적 로깅 사용 - 구조적 로깅은 로그 메시지를 구조화된 방식으로 형식화하여 로그 데이터를 더 쉽게 검색, 필터링 및 분석할 수 있도록 합니다. 로그에서 정보를 쉽게 추출할 수 있도록 일반 텍스트 대신 JSON 또는 기타 구조화된 로깅 형식을 사용하세요.
4. 민감한 정보를 로깅하지 않기 - 비밀번호, API 키, 기타 자격 증명과 같은 민감한 정보를 Kubernetes 로그에 로깅하지 마세요. 대신 환경 변수나 시크릿을 사용하여 이 정보를 안전하게 저장하세요.
5. 컨텍스트 정보 포함 - 타임스탬프, 호스트 이름, 요청 ID와 같은 컨텍스트 정보를 로그에 포함하면 로그 이벤트의 상관 관계를 파악하고 문제를 해결하기가 더 쉬워집니다.
6. 개인정보 정보 태그 지정:
민감한 데이터의 보안과 개인정보 보호를 보장하려면 로그에 있는 민감한 정보에 태그를 지정하거나 마스킹하는 것이 좋습니다. "priv" 또는 "****"와 같은 표준화된 형식을 사용하여 비밀번호, 신용카드 번호 또는 개인 식별 정보(PII)와 같은 민감한 데이터를 식별하고 마스킹할 수 있습니다.
7. 다양한 로그 수준 사용:
다양한 로그 수준을 활용하면 심각도나 중요도에 따라 로그 메시지를 분류할 수 있습니다. 일반적인 로그 수준에는 디버그, 정보, 경고, 오류, 중요 등이 있습니다. 적절한 로그 수준을 사용하면 문제 해결 및 디버깅 중에 중요도에 따라 로그 메시지를 필터링하고 우선 순위를 지정할 수 있습니다.
8. 로그를 로그 서버로 스트리밍하기:
로컬 로그 파일에만 의존하기보다는 로그를 중앙 집중식 로그 서버나 로그 관리 시스템으로 스트리밍하는 것이 좋습니다. 이렇게 하면 로그를 중앙에서 수집하고 저장할 수 있으므로 로그를 더 쉽게 검색, 분석하고 장기간 보관할 수 있습니다. 널리 사용되는 로그 서버 및 관리 시스템으로는 Elasticsearch, Splunk, Graylog 등이 있습니다.
9. 로그 로테이션 활성화:
로그 순환을 구성하여 로그 파일이 무한정 증가하여 디스크 공간을 과도하게 소모하지 않도록 하세요. 로그 순환 매개 변수를 설정하여 로그 파일 크기, 보존할 로그 파일 수, 순환 빈도를 제어할 수 있습니다. 이렇게 하면 로그를 효율적으로 관리하고 디스크 공간 문제를 방지할 수 있습니다.

kubectl logs는 쿠버네티스에서 로그를 검색하는 표준 명령어이지만, 추가 기능과 향상된 로그 수집 기능을 제공하는 몇 가지 오픈소스 CLI 도구도 사용할 수 있다. 그러한 도구 중 하나는 여러 파드에서 동시에 로그를 추적할 수 있는 kubetail입니다. 다음은 쿠버네티스에서 로그 수집에 사용할 수 있는 몇 가지 오픈소스 CLI 도구이다:

1. kubetail
Kubetail은 쿠버네티스 클러스터 내의 여러 파드에서 로그를 추적할 수 있는 간단한 유틸리티입니다. 여러 파드의 로그를 집계하여 터미널로 스트리밍하므로 다양한 소스의 실시간 로그를 한 번에 볼 수 있습니다. Kubetail은 분산 시스템 문제를 해결하거나 여러 파드에서 애플리케이션 동작을 모니터링할 때 특히 유용합니다.
2. Stern:
Stern은 Kubernetes를 위해 특별히 설계된 또 다른 강력한 로그 테일링 도구입니다. 이 도구를 사용하면 Kubernetes 클러스터 내의 여러 파드와 컨테이너에서 로그를 추적할 수 있으며, 쉽게 식별할 수 있도록 색상으로 구분된 출력을 제공합니다. Stern은 또한 정규식 기반 필터링을 지원하므로 특정 로그 메시지나 패턴에 편리하게 집중할 수 있습니다.
3. Kail:
Kail은 Kubernetes 클러스터의 여러 파드에서 로그 스트리밍과 테일링을 가능하게 하는 CLI 도구입니다. 원시 및 JSON 형식의 로그 출력을 모두 지원하므로 다양한 사용 사례에 유연하게 사용할 수 있습니다. Kail은 레이블이나 네임스페이스를 기반으로 로그를 필터링하는 옵션도 제공하므로 필요에 따라 로그 출력 범위를 좁힐 수 있습니다.
4. Logcli:
Logcli는 Loki 에코시스템의 일부로, 수평적 확장이 가능한 로그 집계 시스템인 Loki에 저장된 로그를 쿼리할 수 있는 명령줄 인터페이스를 제공합니다. 레이블, 시간 범위, 로그 수준 등 다양한 매개변수를 기반으로 로그를 검색하고 검색할 수 있습니다. Logcli는 Loki 기반의 중앙 집중식 로깅 솔루션이 있고 로그를 효율적으로 쿼리하고 분석하고자 할 때 유용합니다.

이러한 오픈 소스 CLI 도구는 쿠버네티스에서 로그 수집 및 분석을 위한 추가 기능과 유연성을 제공합니다. 특정 요구사항에 따라 필요에 가장 적합하고 기존 로깅 인프라와 잘 통합되는 도구를 선택할 수 있습니다.

타사 도구를 사용할 때는 신뢰할 수 있는 출처에서 제공하는 도구인지 확인하고 설치 및 사용 지침은 해당 설명서를 검토하세요.

Kubernetes 환경에서 로그를 확인하는 데 사용할 수 있는 다양한 명령어가 있습니다. : kubetail